{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path as osp\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'D:\\\\PycharmProjects\\\\AMMISproject\\\\data\\\\processed_data'\n",
    "dataset = 'dataco'\n",
    "\n",
    "x_train_std = joblib.load(osp.join(data_dir, dataset, 'x_train_std.joblib'))\n",
    "x_test_std = joblib.load(osp.join(data_dir, dataset, 'x_test_std.joblib'))\n",
    "\n",
    "x_train = joblib.load(osp.join(data_dir, dataset, 'x_train.joblib'))\n",
    "x_test = joblib.load(osp.join(data_dir, dataset, 'x_test.joblib'))\n",
    "\n",
    "y_train = joblib.load(osp.join(data_dir, dataset, 'y_train.joblib'))\n",
    "y_test = joblib.load(osp.join(data_dir, dataset, 'y_test.joblib'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the training set:  (138212, 38)\n",
      "Shape of the test set:  (34553, 38)\n",
      "Shape of the trainigb targets:  (138212,)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of the training set: ', x_train.shape)\n",
    "print('Shape of the test set: ', x_test.shape)\n",
    "print('Shape of the trainigb targets: ', y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create main components for TabCBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape:  (38,)\n",
      "Number of outputs:  2\n"
     ]
    }
   ],
   "source": [
    "# Parameters defining the architecture we will use\n",
    "\n",
    "input_shape = x_train.shape[1:]\n",
    "num_outputs = len(set(y_train))\n",
    "encoder_units = [16, 16]\n",
    "decoder_units = [16]\n",
    "latent_dims = 16     \n",
    "learning_rate = 0.001  \n",
    "validation_size = 0.1 \n",
    "\n",
    "print('Input shape: ', input_shape)\n",
    "print('Number of outputs: ', num_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"encoder\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"encoder\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ encoder_dense_0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">624</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ encoder_dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ encoder_bypass_channel (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_5 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ encoder_dense_0 (\u001b[38;5;33mDense\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m624\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ encoder_dense_1 (\u001b[38;5;33mDense\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m272\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ encoder_bypass_channel (\u001b[38;5;33mDense\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m272\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,168</span> (4.56 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,168\u001b[0m (4.56 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,168</span> (4.56 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,168\u001b[0m (4.56 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Next, we build the feature to latent code encoder model (i.e., phi)\n",
    "\n",
    "encoder_inputs = tf.keras.Input(shape=input_shape)\n",
    "encoder_compute_graph = encoder_inputs\n",
    "\n",
    "# Include the fully connected bottleneck here\n",
    "for i, units in enumerate(encoder_units):\n",
    "    encoder_compute_graph = tf.keras.layers.Dense(\n",
    "        units,\n",
    "        activation='relu',\n",
    "        name=f\"encoder_dense_{i}\",\n",
    "    )(encoder_compute_graph)\n",
    "\n",
    "# TIme to generate the latent code here\n",
    "encoder_compute_graph = tf.keras.layers.Dense(\n",
    "    latent_dims,\n",
    "    activation=None,\n",
    "    name=\"encoder_bypass_channel\",\n",
    ")(encoder_compute_graph)\n",
    "\n",
    "encoder = tf.keras.Model(\n",
    "    encoder_inputs,\n",
    "    encoder_compute_graph,\n",
    "    name=\"encoder\",\n",
    ")\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"decoder\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"decoder\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ sequential (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">289</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ sequential (\u001b[38;5;33mSequential\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m289\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">289</span> (1.13 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m289\u001b[0m (1.13 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">289</span> (1.13 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m289\u001b[0m (1.13 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Then, we build the concept to label model  (i.e., the label predictor f)\n",
    "\n",
    "decoder_inputs = tf.keras.Input(shape=[latent_dims])\n",
    "decoder_layers = [\n",
    "    tf.keras.layers.Dense(\n",
    "        units,\n",
    "        activation=tf.nn.relu,\n",
    "        name=f\"decoder_dense_{i+1}\",\n",
    "    ) for i, units in enumerate(decoder_units)\n",
    "]\n",
    "decoder_graph = tf.keras.Sequential(decoder_layers + [\n",
    "    tf.keras.layers.Dense(\n",
    "        num_outputs if num_outputs > 2 else 1,\n",
    "        activation=None,\n",
    "        name=\"decoder_model_output\",\n",
    "    )\n",
    "])\n",
    "decoder = tf.keras.Model(\n",
    "    decoder_inputs,\n",
    "    decoder_graph(decoder_inputs),\n",
    "    name=\"decoder\",\n",
    ")\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"complete_model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"complete_model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ encoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">289</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_6 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ encoder (\u001b[38;5;33mFunctional\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │         \u001b[38;5;34m1,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder (\u001b[38;5;33mFunctional\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m289\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,457</span> (5.69 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,457\u001b[0m (5.69 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,457</span> (5.69 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,457\u001b[0m (5.69 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We then put them both together to make an end-to-end model we can pretrain\n",
    "\n",
    "end_to_end_inputs = tf.keras.Input(shape=input_shape)\n",
    "latent = encoder(end_to_end_inputs)\n",
    "end_to_end_model_compute_graph = decoder(latent)\n",
    "# Now time to collapse all the concepts again back into a single vector\n",
    "end_to_end_model = tf.keras.Model(\n",
    "    end_to_end_inputs,\n",
    "    end_to_end_model_compute_graph,\n",
    "    name=\"complete_model\",\n",
    ")\n",
    "end_to_end_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate),\n",
    "    loss=(\n",
    "        tf.keras.losses.BinaryCrossentropy(from_logits=True) if (num_outputs <= 2)\n",
    "        else tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    ),\n",
    "    metrics=[\n",
    "        \"accuracy\" if (num_outputs <= 2)\n",
    "        else \"sparse_categorical_accuracy\"\n",
    "    ],\n",
    ")\n",
    "end_to_end_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent code model pre-training (using end-to-end model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6079 - loss: 0.6418 - val_accuracy: 0.6927 - val_loss: 0.5508\n",
      "Epoch 2/70\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 886us/step - accuracy: 0.6940 - loss: 0.5464 - val_accuracy: 0.6942 - val_loss: 0.5433\n",
      "Epoch 3/70\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - accuracy: 0.6945 - loss: 0.5414 - val_accuracy: 0.6946 - val_loss: 0.5420\n",
      "Epoch 4/70\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 822us/step - accuracy: 0.6972 - loss: 0.5380 - val_accuracy: 0.6948 - val_loss: 0.5423\n",
      "Epoch 5/70\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850us/step - accuracy: 0.6971 - loss: 0.5383 - val_accuracy: 0.6941 - val_loss: 0.5415\n",
      "Epoch 6/70\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step - accuracy: 0.6957 - loss: 0.5385 - val_accuracy: 0.6946 - val_loss: 0.5410\n",
      "Epoch 7/70\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - accuracy: 0.6967 - loss: 0.5373 - val_accuracy: 0.6948 - val_loss: 0.5410\n",
      "Epoch 8/70\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 864us/step - accuracy: 0.6985 - loss: 0.5368 - val_accuracy: 0.6949 - val_loss: 0.5412\n",
      "Epoch 9/70\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 858us/step - accuracy: 0.6978 - loss: 0.5357 - val_accuracy: 0.6946 - val_loss: 0.5404\n",
      "Epoch 10/70\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829us/step - accuracy: 0.6980 - loss: 0.5350 - val_accuracy: 0.6948 - val_loss: 0.5411\n",
      "Epoch 11/70\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 955us/step - accuracy: 0.6998 - loss: 0.5346 - val_accuracy: 0.6944 - val_loss: 0.5407\n",
      "Epoch 12/70\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 880us/step - accuracy: 0.7002 - loss: 0.5329 - val_accuracy: 0.6939 - val_loss: 0.5403\n",
      "Epoch 13/70\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 940us/step - accuracy: 0.6974 - loss: 0.5351 - val_accuracy: 0.6946 - val_loss: 0.5403\n",
      "Epoch 14/70\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - accuracy: 0.6973 - loss: 0.5334 - val_accuracy: 0.6950 - val_loss: 0.5401\n",
      "Epoch 15/70\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - accuracy: 0.6970 - loss: 0.5360 - val_accuracy: 0.6945 - val_loss: 0.5403\n",
      "Epoch 16/70\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829us/step - accuracy: 0.7002 - loss: 0.5327 - val_accuracy: 0.6948 - val_loss: 0.5417\n",
      "Epoch 17/70\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - accuracy: 0.6973 - loss: 0.5350 - val_accuracy: 0.6944 - val_loss: 0.5399\n",
      "Epoch 18/70\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 884us/step - accuracy: 0.6996 - loss: 0.5332 - val_accuracy: 0.6946 - val_loss: 0.5405\n",
      "Epoch 19/70\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 872us/step - accuracy: 0.6993 - loss: 0.5317 - val_accuracy: 0.6936 - val_loss: 0.5402\n",
      "Epoch 20/70\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - accuracy: 0.6991 - loss: 0.5328 - val_accuracy: 0.6953 - val_loss: 0.5401\n",
      "Epoch 21/70\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 974us/step - accuracy: 0.6981 - loss: 0.5337 - val_accuracy: 0.6951 - val_loss: 0.5407\n",
      "Epoch 22/70\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step - accuracy: 0.6964 - loss: 0.5354 - val_accuracy: 0.6927 - val_loss: 0.5409\n",
      "Epoch 23/70\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838us/step - accuracy: 0.6997 - loss: 0.5320 - val_accuracy: 0.6950 - val_loss: 0.5422\n",
      "Epoch 24/70\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 847us/step - accuracy: 0.7009 - loss: 0.5309 - val_accuracy: 0.6938 - val_loss: 0.5401\n",
      "Epoch 25/70\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - accuracy: 0.6990 - loss: 0.5315 - val_accuracy: 0.6948 - val_loss: 0.5402\n",
      "Epoch 26/70\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 865us/step - accuracy: 0.6992 - loss: 0.5310 - val_accuracy: 0.6936 - val_loss: 0.5404\n",
      "Epoch 27/70\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step - accuracy: 0.6983 - loss: 0.5318 - val_accuracy: 0.6934 - val_loss: 0.5390\n",
      "Epoch 28/70\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - accuracy: 0.6991 - loss: 0.5313 - val_accuracy: 0.6947 - val_loss: 0.5396\n",
      "Epoch 29/70\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 857us/step - accuracy: 0.6982 - loss: 0.5316 - val_accuracy: 0.6933 - val_loss: 0.5392\n",
      "Epoch 30/70\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829us/step - accuracy: 0.6974 - loss: 0.5324 - val_accuracy: 0.6937 - val_loss: 0.5395\n",
      "Epoch 31/70\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - accuracy: 0.6977 - loss: 0.5313 - val_accuracy: 0.6942 - val_loss: 0.5395\n",
      "Epoch 32/70\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 971us/step - accuracy: 0.6978 - loss: 0.5316 - val_accuracy: 0.6943 - val_loss: 0.5384\n",
      "Epoch 33/70\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875us/step - accuracy: 0.6952 - loss: 0.5327 - val_accuracy: 0.6952 - val_loss: 0.5403\n",
      "Epoch 34/70\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 871us/step - accuracy: 0.6971 - loss: 0.5307 - val_accuracy: 0.6920 - val_loss: 0.5401\n",
      "Epoch 35/70\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 969us/step - accuracy: 0.7004 - loss: 0.5292 - val_accuracy: 0.6946 - val_loss: 0.5391\n",
      "Epoch 36/70\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 869us/step - accuracy: 0.6977 - loss: 0.5302 - val_accuracy: 0.6941 - val_loss: 0.5390\n",
      "Epoch 37/70\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 962us/step - accuracy: 0.7000 - loss: 0.5298 - val_accuracy: 0.6940 - val_loss: 0.5389\n",
      "Epoch 38/70\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 965us/step - accuracy: 0.6984 - loss: 0.5307 - val_accuracy: 0.6948 - val_loss: 0.5395\n",
      "Epoch 39/70\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 939us/step - accuracy: 0.6991 - loss: 0.5302 - val_accuracy: 0.6952 - val_loss: 0.5394\n",
      "Epoch 40/70\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7005 - loss: 0.5286 - val_accuracy: 0.6943 - val_loss: 0.5388\n",
      "Epoch 41/70\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905us/step - accuracy: 0.7005 - loss: 0.5282 - val_accuracy: 0.6950 - val_loss: 0.5404\n",
      "Epoch 42/70\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 898us/step - accuracy: 0.7002 - loss: 0.5286 - val_accuracy: 0.6945 - val_loss: 0.5386\n",
      "Epoch 43/70\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903us/step - accuracy: 0.6990 - loss: 0.5295 - val_accuracy: 0.6948 - val_loss: 0.5389\n",
      "Epoch 44/70\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 857us/step - accuracy: 0.6997 - loss: 0.5288 - val_accuracy: 0.6932 - val_loss: 0.5390\n",
      "Epoch 45/70\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step - accuracy: 0.7000 - loss: 0.5286 - val_accuracy: 0.6942 - val_loss: 0.5391\n",
      "Epoch 46/70\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 866us/step - accuracy: 0.6974 - loss: 0.5314 - val_accuracy: 0.6943 - val_loss: 0.5400\n",
      "Epoch 47/70\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - accuracy: 0.7008 - loss: 0.5285 - val_accuracy: 0.6941 - val_loss: 0.5383\n",
      "Epoch 48/70\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step - accuracy: 0.7012 - loss: 0.5276 - val_accuracy: 0.6945 - val_loss: 0.5380\n",
      "Epoch 49/70\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - accuracy: 0.7021 - loss: 0.5274 - val_accuracy: 0.6937 - val_loss: 0.5393\n",
      "Epoch 50/70\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 933us/step - accuracy: 0.7014 - loss: 0.5263 - val_accuracy: 0.6938 - val_loss: 0.5383\n",
      "Epoch 51/70\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - accuracy: 0.7006 - loss: 0.5274 - val_accuracy: 0.6943 - val_loss: 0.5396\n",
      "Epoch 52/70\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 884us/step - accuracy: 0.7014 - loss: 0.5268 - val_accuracy: 0.6926 - val_loss: 0.5389\n",
      "Epoch 53/70\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 900us/step - accuracy: 0.7019 - loss: 0.5268 - val_accuracy: 0.6955 - val_loss: 0.5386\n",
      "Epoch 54/70\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 874us/step - accuracy: 0.7002 - loss: 0.5277 - val_accuracy: 0.6946 - val_loss: 0.5388\n",
      "Epoch 55/70\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step - accuracy: 0.6998 - loss: 0.5281 - val_accuracy: 0.6945 - val_loss: 0.5390\n",
      "Epoch 56/70\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - accuracy: 0.6985 - loss: 0.5285 - val_accuracy: 0.6940 - val_loss: 0.5386\n",
      "Epoch 57/70\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step - accuracy: 0.7003 - loss: 0.5275 - val_accuracy: 0.6946 - val_loss: 0.5381\n",
      "Epoch 58/70\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844us/step - accuracy: 0.6991 - loss: 0.5291 - val_accuracy: 0.6954 - val_loss: 0.5396\n",
      "Epoch 59/70\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 995us/step - accuracy: 0.7022 - loss: 0.5271 - val_accuracy: 0.6950 - val_loss: 0.5381\n",
      "Epoch 60/70\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 921us/step - accuracy: 0.6998 - loss: 0.5273 - val_accuracy: 0.6909 - val_loss: 0.5394\n",
      "Epoch 61/70\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903us/step - accuracy: 0.7012 - loss: 0.5270 - val_accuracy: 0.6952 - val_loss: 0.5381\n",
      "Epoch 62/70\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 892us/step - accuracy: 0.6996 - loss: 0.5276 - val_accuracy: 0.6927 - val_loss: 0.5392\n",
      "Epoch 63/70\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 886us/step - accuracy: 0.7001 - loss: 0.5274 - val_accuracy: 0.6961 - val_loss: 0.5380\n",
      "Epoch 64/70\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 958us/step - accuracy: 0.7023 - loss: 0.5254 - val_accuracy: 0.6922 - val_loss: 0.5388\n",
      "Epoch 65/70\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 939us/step - accuracy: 0.6993 - loss: 0.5273 - val_accuracy: 0.6952 - val_loss: 0.5389\n",
      "Epoch 66/70\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 993us/step - accuracy: 0.7006 - loss: 0.5261 - val_accuracy: 0.6933 - val_loss: 0.5382\n",
      "Epoch 67/70\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 947us/step - accuracy: 0.7017 - loss: 0.5259 - val_accuracy: 0.6951 - val_loss: 0.5376\n",
      "Epoch 68/70\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - accuracy: 0.7006 - loss: 0.5270 - val_accuracy: 0.6947 - val_loss: 0.5373\n",
      "Epoch 69/70\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - accuracy: 0.6994 - loss: 0.5255 - val_accuracy: 0.6943 - val_loss: 0.5377\n",
      "Epoch 70/70\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 857us/step - accuracy: 0.7006 - loss: 0.5252 - val_accuracy: 0.6945 - val_loss: 0.5382\n"
     ]
    }
   ],
   "source": [
    "pretrain_epochs = 70\n",
    "batch_size = 512\n",
    "pretrain_hist = end_to_end_model.fit(\n",
    "    x=x_train_std,\n",
    "    y=y_train,\n",
    "    epochs=pretrain_epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_split=validation_size,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 994us/step\n",
      "Pretrained model task accuracy: 69.66%\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "import sklearn\n",
    "\n",
    "# We will accumulate all metrics/results in the same dictionary\n",
    "results = {}\n",
    "\n",
    "# Make test predictions for the test set\n",
    "end_to_end_preds = end_to_end_model.predict(\n",
    "    x_test_std,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "# Get accuracy/AUC using the corresponding test labels\n",
    "if ((len(end_to_end_preds.shape) == 2)) and (end_to_end_preds.shape[-1] >= 2):\n",
    "    # Then we are using multi-class outputs\n",
    "    preds = scipy.special.softmax(\n",
    "        end_to_end_preds,\n",
    "        axis=-1,\n",
    "    )\n",
    "\n",
    "    one_hot_labels = tf.keras.utils.to_categorical(y_test)\n",
    "    results['pre_train_acc'] = sklearn.metrics.accuracy_score(\n",
    "        y_test,\n",
    "        np.argmax(preds, axis=-1),\n",
    "    )\n",
    "\n",
    "    # And select just the labels that are in fact being used\n",
    "    results['pre_train_auc'] = sklearn.metrics.roc_auc_score(\n",
    "        one_hot_labels,\n",
    "        preds,\n",
    "        multi_class='ovo',\n",
    "    )\n",
    "else:\n",
    "    # Otherwise we are dealing with simple binary outputs\n",
    "    if np.min(end_to_end_preds) < 0.0 or np.max(end_to_end_preds) > 1:\n",
    "        # Then we assume that we have outputed logits\n",
    "        end_to_end_preds = tf.math.sigmoid(end_to_end_preds).numpy()\n",
    "    end_to_end_preds = (end_to_end_preds >= 0.5).astype(np.int32)\n",
    "    results['pre_train_acc'] = sklearn.metrics.accuracy_score(\n",
    "        y_test,\n",
    "        end_to_end_preds,\n",
    "    )\n",
    "    results['pre_train_auc'] = sklearn.metrics.roc_auc_score(\n",
    "        y_test,\n",
    "        end_to_end_preds,\n",
    "    )\n",
    "print(f\"Pretrained model task accuracy: {results['pre_train_acc']*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct TabCBM\n",
    "\n",
    "We are now ready to construct a TabCBM. For this, we will first compute the\n",
    "empirical covariance matrix in order for us to learn useful masks using a\n",
    "similar approach to that proposed by SEFS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.00000000e+00  1.00105563e-03  8.38634556e-03 ... -3.34490471e-03\n",
      "   6.45576389e-03  7.41082360e-04]\n",
      " [ 1.00105563e-03  1.00000000e+00  2.93211877e-03 ...  1.57344435e-03\n",
      "  -2.49050682e-03 -4.45254638e-03]\n",
      " [ 8.38634556e-03  2.93211877e-03  1.00000000e+00 ...  3.03096663e-03\n",
      "   5.79808624e-03  1.24462552e-03]\n",
      " ...\n",
      " [-3.34490471e-03  1.57344435e-03  3.03096663e-03 ...  1.00000000e+00\n",
      "  -1.99639348e-01 -1.38666258e-01]\n",
      " [ 6.45576389e-03 -2.49050682e-03  5.79808624e-03 ... -1.99639348e-01\n",
      "   1.00000000e+00 -2.07627716e-01]\n",
      " [ 7.41082360e-04 -4.45254638e-03  1.24462552e-03 ... -1.38666258e-01\n",
      "  -2.07627716e-01  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Construct the training set's empirical covariance matrix\n",
    "# NOTE: This step can be very computationally expensive/intractable in large\n",
    "#       datasets. In those cases, one may ignore the covariance matrix when\n",
    "#       performing TabCBM's pretraining at the potential cost of performance or\n",
    "#       more accurate concept discovery.\n",
    "cov_mat = np.corrcoef(x_train.T)\n",
    "print(cov_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tabcbm.models'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtabcbm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtabcbm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TabCBM\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Number of concepts we want to discover\u001b[39;00m\n\u001b[0;32m      4\u001b[0m n_concepts \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tabcbm.models'"
     ]
    }
   ],
   "source": [
    "from tabcbm.models.tabcbm import TabCBM\n",
    "\n",
    "# Number of concepts we want to discover\n",
    "n_concepts = 2\n",
    "\n",
    "# Set the weights for the different regularisers in the loss\n",
    "coherence_reg_weight = 0.1  # $lambda_{co}\n",
    "diversity_reg_weight = 5 # $lambda_{div}\n",
    "feature_selection_reg_weight = 5 # $lambda_{spec}\n",
    "gate_estimator_weight = 10 # Gate prediction regularizer for SEFS's pre-text task\n",
    "\n",
    "# Select how many neighbors to use for the coherency loss (must be less than\n",
    "# the batch size!)\n",
    "top_k = 256\n",
    "\n",
    "# Generate a dictionary with the parameters to use for TabCBM as we will have\n",
    "# to use the same parameters twice:\n",
    "tab_cbm_params = dict(\n",
    "    features_to_concepts_model=encoder,  # The $\\phi$ sub-model\n",
    "    concepts_to_labels_model=decoder,  # The $f$ sub-model\n",
    "    latent_dims=latent_dims,  # The dimensionality of the concept embeddings $m$\n",
    "    n_concepts=n_concepts,  # The number of concepts to discover $k^\\prime$\n",
    "    cov_mat=cov_mat,  # The empirical covariance matrix\n",
    "    loss_fn=end_to_end_model.loss,  # The downstream task loss function\n",
    "    # Then we provide all the regularizers weights\n",
    "    coherence_reg_weight=coherence_reg_weight,\n",
    "    diversity_reg_weight=diversity_reg_weight,\n",
    "    feature_selection_reg_weight=feature_selection_reg_weight,\n",
    "    gate_estimator_weight=gate_estimator_weight,\n",
    "    top_k=top_k,\n",
    "\n",
    "    # And indicate that we will not be providing any supervised concepts! Change\n",
    "    # this is training concepts (e.g., `c_train`) are provided/known during\n",
    "    # training\n",
    "    n_supervised_concepts=0,\n",
    "    concept_prediction_weight=0,\n",
    "\n",
    "    # The accuracy metric to use for logging performance\n",
    "    acc_metric=(\n",
    "        lambda y_true, y_pred: tf.math.reduce_mean(\n",
    "            tf.keras.metrics.sparse_categorical_accuracy(\n",
    "                y_true,\n",
    "                y_pred,\n",
    "            )\n",
    "        )\n",
    "    ),\n",
    "\n",
    "    # ANd architectural details of the self-supervised reconstruction modules\n",
    "    concept_generator_units=[64],\n",
    "    rec_model_units=[64],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
