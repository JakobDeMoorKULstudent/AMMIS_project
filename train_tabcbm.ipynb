{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Define the groud-truth concepts  \n",
    "2) Train the TabCBM in unsup-concept setting\n",
    "3) Evaluate performance using several metrics \n",
    "4) Supervised-concepts setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import joblib\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path as osp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tabcbm.models.architectures import construct_encoder, construct_decoder\n",
    "from tabcbm.models.architectures import construct_end_to_end_model\n",
    "from tabcbm.models.tabcbm import TabCBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the training set:  (138212, 38)\n",
      "Shape of the test set:  (34553, 38)\n",
      "Shape of the trainigb targets:  (138212,)\n"
     ]
    }
   ],
   "source": [
    "# Reading already preprocessed train and test data \n",
    "\n",
    "data_dir = 'D:\\\\PycharmProjects\\\\AMMISproject\\\\data\\\\processed_data'\n",
    "dataset = 'dataco'\n",
    "\n",
    "x_train_std = joblib.load(osp.join(data_dir, dataset, 'x_train_std.joblib'))\n",
    "x_test_std = joblib.load(osp.join(data_dir, dataset, 'x_test_std.joblib'))\n",
    "\n",
    "x_train = joblib.load(osp.join(data_dir, dataset, 'x_train.joblib'))\n",
    "x_test = joblib.load(osp.join(data_dir, dataset, 'x_test.joblib'))\n",
    "\n",
    "y_train = joblib.load(osp.join(data_dir, dataset, 'y_train.joblib'))\n",
    "y_test = joblib.load(osp.join(data_dir, dataset, 'y_test.joblib'))\n",
    "\n",
    "print('Shape of the training set: ', x_train_std.shape)\n",
    "print('Shape of the test set: ', x_test_std.shape)\n",
    "print('Shape of the trainigb targets: ', y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the concepts \n",
    "\n",
    "aggregated_concepts = {\n",
    "    'Shipment': ['Type', 'Days for shipment (scheduled)', 'Shipping Mode'],\n",
    "    'Customer': ['Customer Zipcode', 'Customer Segment'],\n",
    "    'Department': ['Department Name', 'Market'],\n",
    "    'Store': ['Latitude', 'Longitude'],\n",
    "    'Order': ['Order Id', 'Order City', 'Order Country', 'order date (DateOrders)',\n",
    "              'Order Profit Per Order', 'Order Status', 'Sales', 'Order Item Discount',\n",
    "              'order_year', 'order_month', 'order_day'],\n",
    "    'ProductCategory': ['Category Name']\n",
    "}\n",
    "\n",
    "# In the preprocessed data the naming of the columns differs, so we have to define\n",
    "# expanded features and put them as a value of a corresponding concept\n",
    "extended_concepts = {}\n",
    "for concept, features in aggregated_concepts.items():\n",
    "    extended_features = []\n",
    "    for value in features:\n",
    "            [extended_features.append(column) for column in x_test.columns if value in column]\n",
    "   \n",
    "    extended_concepts[concept] = extended_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating masks for each concept \n",
    "\n",
    "concepts_num = len(aggregated_concepts)\n",
    "total_features_num = x_test.shape[1] \n",
    "\n",
    "concepts_masks = pd.DataFrame(0, columns=x_test.columns, index=list(aggregated_concepts.keys()))\n",
    "\n",
    "for concept, features in extended_concepts.items():\n",
    "    for feature in features:\n",
    "        concepts_masks.loc[concept, feature] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Days for shipment (scheduled)    1\n",
       "Category Name                    0\n",
       "Customer Zipcode                 0\n",
       "Department Name                  0\n",
       "Latitude                         0\n",
       "Longitude                        0\n",
       "Order City                       0\n",
       "Order Country                    0\n",
       "Sales                            0\n",
       "Order Id                         0\n",
       "Order Item Discount              0\n",
       "Order Profit Per Order           0\n",
       "order_year                       0\n",
       "order_month                      0\n",
       "order_day                        0\n",
       "Type_CASH                        1\n",
       "Type_DEBIT                       1\n",
       "Type_PAYMENT                     1\n",
       "Type_TRANSFER                    1\n",
       "Customer Segment_Consumer        0\n",
       "Customer Segment_Corporate       0\n",
       "Customer Segment_Home Office     0\n",
       "Market_Africa                    0\n",
       "Market_Europe                    0\n",
       "Market_LATAM                     0\n",
       "Market_Pacific Asia              0\n",
       "Market_USCA                      0\n",
       "Shipping Mode_First Class        1\n",
       "Shipping Mode_Same Day           1\n",
       "Shipping Mode_Second Class       1\n",
       "Shipping Mode_Standard Class     1\n",
       "Order Status_CLOSED              0\n",
       "Order Status_COMPLETE            0\n",
       "Order Status_ON_HOLD             0\n",
       "Order Status_PAYMENT_REVIEW      0\n",
       "Order Status_PENDING             0\n",
       "Order Status_PENDING_PAYMENT     0\n",
       "Order Status_PROCESSING          0\n",
       "Name: Shipment, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking whether the features correspond to the defined concept \"Shipment\" \n",
    "\n",
    "concepts_masks.loc['Shipment', :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create main components for TabCBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape:  (38,)\n",
      "Number of outputs:  2\n"
     ]
    }
   ],
   "source": [
    "# Parameters defining the architecture we will use\n",
    "\n",
    "input_shape = x_train_std.shape[1:]\n",
    "num_outputs = len(set(y_train))\n",
    "encoder_units = [16, 16]\n",
    "decoder_units = [16]\n",
    "latent_dims = 16\n",
    "learning_rate = 0.001\n",
    "validation_size = 0.1\n",
    "\n",
    "print('Input shape: ', input_shape)\n",
    "print('Number of outputs: ', num_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we build the feature to latent code encoder model (i.e., phi)\n",
    "encoder = construct_encoder(input_shape, encoder_units, latent_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then, we build the concept to label model  (i.e., the label predictor f)\n",
    "\n",
    "decoder_inputs = tf.keras.Input(shape=[latent_dims])\n",
    "decoder_graph = construct_decoder(decoder_units, num_outputs)\n",
    "decoder = tf.keras.Model(\n",
    "    decoder_inputs,\n",
    "    decoder_graph(decoder_inputs),\n",
    "    name=\"decoder\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"complete_model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"complete_model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ encoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">289</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_18 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ encoder (\u001b[38;5;33mFunctional\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │         \u001b[38;5;34m1,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder (\u001b[38;5;33mFunctional\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m289\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,457</span> (5.69 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,457\u001b[0m (5.69 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,457</span> (5.69 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,457\u001b[0m (5.69 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - binary_accuracy: 0.5762 - loss: 0.6290 - val_binary_accuracy: 0.6929 - val_loss: 0.5467\n",
      "Epoch 2/30\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.6935 - loss: 0.5431 - val_binary_accuracy: 0.6945 - val_loss: 0.5430\n",
      "Epoch 3/30\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.6980 - loss: 0.5372 - val_binary_accuracy: 0.6935 - val_loss: 0.5421\n",
      "Epoch 4/30\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.6982 - loss: 0.5378 - val_binary_accuracy: 0.6949 - val_loss: 0.5419\n",
      "Epoch 5/30\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.6963 - loss: 0.5379 - val_binary_accuracy: 0.6952 - val_loss: 0.5412\n",
      "Epoch 6/30\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - binary_accuracy: 0.6980 - loss: 0.5358 - val_binary_accuracy: 0.6948 - val_loss: 0.5409\n",
      "Epoch 7/30\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.6983 - loss: 0.5358 - val_binary_accuracy: 0.6950 - val_loss: 0.5410\n",
      "Epoch 8/30\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.6958 - loss: 0.5374 - val_binary_accuracy: 0.6956 - val_loss: 0.5434\n",
      "Epoch 9/30\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.6954 - loss: 0.5369 - val_binary_accuracy: 0.6940 - val_loss: 0.5415\n",
      "Epoch 10/30\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.6987 - loss: 0.5356 - val_binary_accuracy: 0.6949 - val_loss: 0.5410\n",
      "Epoch 11/30\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.6966 - loss: 0.5353 - val_binary_accuracy: 0.6950 - val_loss: 0.5410\n",
      "Epoch 12/30\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.6971 - loss: 0.5357 - val_binary_accuracy: 0.6953 - val_loss: 0.5422\n",
      "Epoch 13/30\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.6994 - loss: 0.5334 - val_binary_accuracy: 0.6950 - val_loss: 0.5412\n",
      "Epoch 14/30\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.6968 - loss: 0.5361 - val_binary_accuracy: 0.6951 - val_loss: 0.5409\n",
      "Epoch 15/30\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.6968 - loss: 0.5352 - val_binary_accuracy: 0.6952 - val_loss: 0.5423\n",
      "Epoch 16/30\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.6985 - loss: 0.5347 - val_binary_accuracy: 0.6949 - val_loss: 0.5414\n",
      "Epoch 17/30\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.6963 - loss: 0.5353 - val_binary_accuracy: 0.6952 - val_loss: 0.5412\n",
      "Epoch 18/30\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.6989 - loss: 0.5341 - val_binary_accuracy: 0.6945 - val_loss: 0.5408\n",
      "Epoch 19/30\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.6954 - loss: 0.5362 - val_binary_accuracy: 0.6944 - val_loss: 0.5413\n",
      "Epoch 20/30\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.6979 - loss: 0.5331 - val_binary_accuracy: 0.6954 - val_loss: 0.5415\n",
      "Epoch 21/30\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.7006 - loss: 0.5317 - val_binary_accuracy: 0.6947 - val_loss: 0.5410\n",
      "Epoch 22/30\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.6968 - loss: 0.5336 - val_binary_accuracy: 0.6946 - val_loss: 0.5408\n",
      "Epoch 23/30\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.6981 - loss: 0.5331 - val_binary_accuracy: 0.6948 - val_loss: 0.5407\n",
      "Epoch 24/30\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.6991 - loss: 0.5335 - val_binary_accuracy: 0.6946 - val_loss: 0.5411\n",
      "Epoch 25/30\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - binary_accuracy: 0.6968 - loss: 0.5333 - val_binary_accuracy: 0.6951 - val_loss: 0.5406\n",
      "Epoch 26/30\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.6962 - loss: 0.5341 - val_binary_accuracy: 0.6939 - val_loss: 0.5403\n",
      "Epoch 27/30\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.6993 - loss: 0.5316 - val_binary_accuracy: 0.6943 - val_loss: 0.5407\n",
      "Epoch 28/30\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.6988 - loss: 0.5319 - val_binary_accuracy: 0.6945 - val_loss: 0.5403\n",
      "Epoch 29/30\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.6982 - loss: 0.5319 - val_binary_accuracy: 0.6946 - val_loss: 0.5400\n",
      "Epoch 30/30\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.6975 - loss: 0.5332 - val_binary_accuracy: 0.6960 - val_loss: 0.5420\n"
     ]
    }
   ],
   "source": [
    "# We then put them both together to make an end-to-end model we can pretrain\n",
    "\n",
    "end_to_end_model, encoder, decoder = construct_end_to_end_model(input_shape,\n",
    "                                                                encoder,\n",
    "                                                                decoder,\n",
    "                                                                num_outputs,\n",
    "                                                                learning_rate)\n",
    "\n",
    "end_to_end_model.summary()\n",
    "\n",
    "pretrain_epochs = 30\n",
    "batch_size = 512\n",
    "pretrain_hist = end_to_end_model.fit(\n",
    "    x=x_train_std,\n",
    "    y=y_train,\n",
    "    epochs=pretrain_epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_split=validation_size,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Pretrained model task accuracy: 69.39%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate pretrained model\n",
    "\n",
    "# We will accumulate all metrics/results in the same dictionary\n",
    "results = {}\n",
    "\n",
    "end_to_end_preds = end_to_end_model.predict(\n",
    "    x_test_std,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "# We assume that we have outputed logits\n",
    "if np.min(end_to_end_preds) < 0.0 or np.max(end_to_end_preds) > 1:\n",
    "    end_to_end_preds = tf.math.sigmoid(end_to_end_preds).numpy()\n",
    "end_to_end_preds = (end_to_end_preds >= 0.5).astype(np.int32)\n",
    "results['pre_train_acc'] = sklearn.metrics.accuracy_score(\n",
    "    y_test,\n",
    "    end_to_end_preds,\n",
    ")\n",
    "results['pre_train_auc'] = sklearn.metrics.roc_auc_score(\n",
    "    y_test,\n",
    "    end_to_end_preds,\n",
    ")\n",
    "print(f\"Pretrained model task accuracy: {results['pre_train_acc']*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct TabCBM\n",
    "\n",
    "For this, we will first compute the empirical covariance matrix in order for us to learn useful masks using a similar approach to that proposed by SEFS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.00000000e+00  1.00105563e-03  8.38634556e-03 ... -3.34490471e-03\n",
      "   6.45576389e-03  7.41082360e-04]\n",
      " [ 1.00105563e-03  1.00000000e+00  2.93211877e-03 ...  1.57344435e-03\n",
      "  -2.49050682e-03 -4.45254638e-03]\n",
      " [ 8.38634556e-03  2.93211877e-03  1.00000000e+00 ...  3.03096663e-03\n",
      "   5.79808624e-03  1.24462552e-03]\n",
      " ...\n",
      " [-3.34490471e-03  1.57344435e-03  3.03096663e-03 ...  1.00000000e+00\n",
      "  -1.99639348e-01 -1.38666258e-01]\n",
      " [ 6.45576389e-03 -2.49050682e-03  5.79808624e-03 ... -1.99639348e-01\n",
      "   1.00000000e+00 -2.07627716e-01]\n",
      " [ 7.41082360e-04 -4.45254638e-03  1.24462552e-03 ... -1.38666258e-01\n",
      "  -2.07627716e-01  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Construct the training set's empirical covariance matrix\n",
    "# NOTE: This step can be very computationally expensive/intractable in large\n",
    "#       datasets. In those cases, one may ignore the covariance matrix when\n",
    "#       performing TabCBM's pretraining at the potential cost of performance or\n",
    "#       more accurate concept discovery.\n",
    "cov_mat = np.corrcoef(x_train_std.T)\n",
    "print(cov_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of concepts we want to discover\n",
    "n_concepts = 6\n",
    "\n",
    "# Set the weights for the different regularisers in the loss\n",
    "coherence_reg_weight = 0.1  # $lambda_{co}\n",
    "diversity_reg_weight = 5  # $lambda_{div}\n",
    "feature_selection_reg_weight = 5  # $lambda_{spec}\n",
    "gate_estimator_weight = 10  # Gate prediction regularizer for SEFS's pre-text task\n",
    "\n",
    "# Select how many neighbors to use for the coherency loss (must be less than the batch size!)\n",
    "top_k = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a dictionary with the parameters to use for TabCBM as we will have\n",
    "# to use the same parameters twice:\n",
    "tab_cbm_params = dict(\n",
    "    features_to_concepts_model=encoder,  # The $\\phi$ sub-model\n",
    "    concepts_to_labels_model=decoder,  # The $f$ sub-model\n",
    "    latent_dims=latent_dims,  # The dimensionality of the concept embeddings $m$\n",
    "    n_concepts=n_concepts,  # The number of concepts to discover $k^\\prime$\n",
    "    cov_mat=cov_mat,  # The empirical covariance matrix\n",
    "    loss_fn=end_to_end_model.loss,  # The downstream task loss function\n",
    "    # Then we provide all the regularizers weights\n",
    "    coherence_reg_weight=coherence_reg_weight,\n",
    "    diversity_reg_weight=diversity_reg_weight,\n",
    "    feature_selection_reg_weight=feature_selection_reg_weight,\n",
    "    gate_estimator_weight=gate_estimator_weight,\n",
    "    top_k=top_k,\n",
    "\n",
    "    # And indicate that we will not be providing any supervised concepts! Change\n",
    "    # this is training concepts (e.g., `c_train`) are provided/known during\n",
    "    # training\n",
    "    n_supervised_concepts=0,\n",
    "    concept_prediction_weight=0,\n",
    "\n",
    "    # The accuracy metric to use for logging performance\n",
    "    acc_metric=(\n",
    "        lambda y_true, y_pred: tf.math.reduce_mean(\n",
    "            tf.keras.metrics.sparse_categorical_accuracy(\n",
    "                y_true,\n",
    "                y_pred,\n",
    "            )\n",
    "        )\n",
    "    ),\n",
    "\n",
    "    # ANd architectural details of the self-supervised reconstruction modules\n",
    "    concept_generator_units=[64],\n",
    "    rec_model_units=[64],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] Assuming independence between features in TabCBM training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PycharmProjects\\AMMISproject\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"tab_cbm\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"tab_cbm\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ decoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">289</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ encoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ sequential_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">11,516</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ concept_generators_0            │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rec_values_model_0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rec_mask_model (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ concept_generators_1            │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ concept_generators_2            │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ concept_generators_3            │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ concept_generators_4            │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ concept_generators_5            │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)                    │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ decoder (\u001b[38;5;33mFunctional\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m289\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ encoder (\u001b[38;5;33mFunctional\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │         \u001b[38;5;34m1,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ sequential_1 (\u001b[38;5;33mSequential\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │        \u001b[38;5;34m11,516\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ concept_generators_0            │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mSequential\u001b[0m)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rec_values_model_0 (\u001b[38;5;33mSequential\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rec_mask_model (\u001b[38;5;33mSequential\u001b[0m)     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ concept_generators_1            │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mSequential\u001b[0m)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ concept_generators_2            │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mSequential\u001b[0m)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ concept_generators_3            │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mSequential\u001b[0m)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ concept_generators_4            │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mSequential\u001b[0m)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ concept_generators_5            │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mSequential\u001b[0m)                    │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,429</span> (52.46 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m13,429\u001b[0m (52.46 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,201</span> (51.57 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m13,201\u001b[0m (51.57 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">228</span> (912.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m228\u001b[0m (912.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Mask Generator Self-supervised Training\n",
    "\n",
    "# Next, we proceed to do the SELF-SUPERVISED TRAINING of the MASK\n",
    "# GENERATORS for TabCBM. For this, we will follow a similar approach\n",
    "# to that of SEFS. Our TabCBM module allows one to do this by setting\n",
    "# the self_supervised_mode flag to True before calling the .fit() method:\n",
    "\n",
    "# We can now construct our TabCBM model which we will first self-supervise!\n",
    "ss_tabcbm = TabCBM(self_supervised_mode=True,  **tab_cbm_params)\n",
    "ss_tabcbm.compile(optimizer=tf.keras.optimizers.Adam(learning_rate,))\n",
    "ss_tabcbm.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TabCBM self-supervised training stage...\n",
      "Epoch 1/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.7823 - avg_mask_rec_loss: 26.4700 - loss: 163.5136 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 0.8006 - val_avg_mask_rec_loss: 6.7000 - val_loss: 45.0035\n",
      "Epoch 2/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.8057 - avg_mask_rec_loss: 6.6508 - loss: 44.7388 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 0.8222 - val_avg_mask_rec_loss: 6.5372 - val_loss: 44.1562\n",
      "Epoch 3/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.8269 - avg_mask_rec_loss: 6.4985 - loss: 43.9527 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 0.8421 - val_avg_mask_rec_loss: 6.4169 - val_loss: 43.5543\n",
      "Epoch 4/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.8464 - avg_mask_rec_loss: 6.3785 - loss: 43.3498 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 0.8605 - val_avg_mask_rec_loss: 6.3039 - val_loss: 42.9865\n",
      "Epoch 5/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.8646 - avg_mask_rec_loss: 6.2882 - loss: 42.9166 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 0.8777 - val_avg_mask_rec_loss: 6.2639 - val_loss: 42.8496\n",
      "Epoch 6/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.8814 - avg_mask_rec_loss: 6.2154 - loss: 42.5807 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 0.8935 - val_avg_mask_rec_loss: 6.1403 - val_loss: 42.2028\n",
      "Epoch 7/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.8970 - avg_mask_rec_loss: 6.1250 - loss: 42.1315 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 0.9081 - val_avg_mask_rec_loss: 6.0509 - val_loss: 41.7541\n",
      "Epoch 8/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.9113 - avg_mask_rec_loss: 6.0325 - loss: 41.6629 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 0.9214 - val_avg_mask_rec_loss: 5.9583 - val_loss: 41.2779\n",
      "Epoch 9/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.9242 - avg_mask_rec_loss: 5.9477 - loss: 41.2314 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 0.9331 - val_avg_mask_rec_loss: 5.8609 - val_loss: 40.7643\n",
      "Epoch 10/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.9356 - avg_mask_rec_loss: 5.8339 - loss: 40.6170 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 0.9436 - val_avg_mask_rec_loss: 5.7630 - val_loss: 40.2396\n",
      "Epoch 11/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.9458 - avg_mask_rec_loss: 5.7577 - loss: 40.2210 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 0.9531 - val_avg_mask_rec_loss: 5.7076 - val_loss: 39.9647\n",
      "Epoch 12/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.9552 - avg_mask_rec_loss: 5.6878 - loss: 39.8581 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 0.9618 - val_avg_mask_rec_loss: 5.6666 - val_loss: 39.7707\n",
      "Epoch 13/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.9637 - avg_mask_rec_loss: 5.6486 - loss: 39.6736 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 0.9698 - val_avg_mask_rec_loss: 5.6318 - val_loss: 39.6091\n",
      "Epoch 14/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.9715 - avg_mask_rec_loss: 5.6285 - loss: 39.5995 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 0.9769 - val_avg_mask_rec_loss: 5.6304 - val_loss: 39.6439\n",
      "Epoch 15/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.9784 - avg_mask_rec_loss: 5.6145 - loss: 39.5576 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 0.9833 - val_avg_mask_rec_loss: 5.6078 - val_loss: 39.5464\n",
      "Epoch 16/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.9846 - avg_mask_rec_loss: 5.5967 - loss: 39.4879 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 0.9890 - val_avg_mask_rec_loss: 5.5884 - val_loss: 39.4646\n",
      "Epoch 17/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.9902 - avg_mask_rec_loss: 5.5778 - loss: 39.4082 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 0.9942 - val_avg_mask_rec_loss: 5.5750 - val_loss: 39.4150\n",
      "Epoch 18/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.9953 - avg_mask_rec_loss: 5.5670 - loss: 39.3741 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 0.9988 - val_avg_mask_rec_loss: 5.5617 - val_loss: 39.3629\n",
      "Epoch 19/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.9998 - avg_mask_rec_loss: 5.5527 - loss: 39.3149 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 1.0029 - val_avg_mask_rec_loss: 5.5425 - val_loss: 39.2722\n",
      "Epoch 20/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 1.0038 - avg_mask_rec_loss: 5.5423 - loss: 39.2767 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 1.0065 - val_avg_mask_rec_loss: 5.5487 - val_loss: 39.3313\n",
      "Epoch 21/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 1.0073 - avg_mask_rec_loss: 5.5333 - loss: 39.2436 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 1.0097 - val_avg_mask_rec_loss: 5.5372 - val_loss: 39.2816\n",
      "Epoch 22/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 1.0104 - avg_mask_rec_loss: 5.5298 - loss: 39.2414 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 1.0126 - val_avg_mask_rec_loss: 5.5282 - val_loss: 39.2444\n",
      "Epoch 23/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 1.0131 - avg_mask_rec_loss: 5.5196 - loss: 39.1964 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 1.0149 - val_avg_mask_rec_loss: 5.5056 - val_loss: 39.1231\n",
      "Epoch 24/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 1.0155 - avg_mask_rec_loss: 5.5079 - loss: 39.1399 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 1.0171 - val_avg_mask_rec_loss: 5.4960 - val_loss: 39.0782\n",
      "Epoch 25/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 1.0175 - avg_mask_rec_loss: 5.4966 - loss: 39.0848 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 1.0189 - val_avg_mask_rec_loss: 5.5187 - val_loss: 39.2253\n",
      "Epoch 26/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 1.0192 - avg_mask_rec_loss: 5.4939 - loss: 39.0788 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 1.0204 - val_avg_mask_rec_loss: 5.4843 - val_loss: 39.0285\n",
      "Epoch 27/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 1.0207 - avg_mask_rec_loss: 5.4876 - loss: 39.0496 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 1.0217 - val_avg_mask_rec_loss: 5.4950 - val_loss: 39.1002\n",
      "Epoch 28/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 1.0220 - avg_mask_rec_loss: 5.4813 - loss: 39.0197 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 1.0228 - val_avg_mask_rec_loss: 5.4796 - val_loss: 39.0144\n",
      "Epoch 29/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 1.0231 - avg_mask_rec_loss: 5.4735 - loss: 38.9797 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 1.0238 - val_avg_mask_rec_loss: 5.4798 - val_loss: 39.0216\n",
      "Epoch 30/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 1.0240 - avg_mask_rec_loss: 5.4696 - loss: 38.9613 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 1.0245 - val_avg_mask_rec_loss: 5.4802 - val_loss: 39.0280\n",
      "Epoch 31/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 1.0246 - avg_mask_rec_loss: 5.4643 - loss: 38.9337 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 1.0251 - val_avg_mask_rec_loss: 5.4636 - val_loss: 38.9320\n",
      "Epoch 32/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 1.0252 - avg_mask_rec_loss: 5.4614 - loss: 38.9198 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 1.0255 - val_avg_mask_rec_loss: 5.4647 - val_loss: 38.9412\n",
      "Epoch 33/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 1.0256 - avg_mask_rec_loss: 5.4521 - loss: 38.8660 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 1.0257 - val_avg_mask_rec_loss: 5.4706 - val_loss: 38.9781\n",
      "Epoch 34/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 1.0258 - avg_mask_rec_loss: 5.4514 - loss: 38.8630 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 1.0259 - val_avg_mask_rec_loss: 5.4478 - val_loss: 38.8417\n",
      "Epoch 35/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 1.0259 - avg_mask_rec_loss: 5.4417 - loss: 38.8058 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 1.0259 - val_avg_mask_rec_loss: 5.4615 - val_loss: 38.9246\n",
      "Epoch 36/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 1.0259 - avg_mask_rec_loss: 5.4403 - loss: 38.7970 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 1.0258 - val_avg_mask_rec_loss: 5.4382 - val_loss: 38.7838\n",
      "Epoch 37/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 1.0257 - avg_mask_rec_loss: 5.4332 - loss: 38.7537 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 1.0256 - val_avg_mask_rec_loss: 5.4413 - val_loss: 38.8011\n",
      "Epoch 38/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 1.0255 - avg_mask_rec_loss: 5.4366 - loss: 38.7727 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 1.0252 - val_avg_mask_rec_loss: 5.4341 - val_loss: 38.7560\n",
      "Epoch 39/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 1.0251 - avg_mask_rec_loss: 5.4291 - loss: 38.7256 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 1.0248 - val_avg_mask_rec_loss: 5.4274 - val_loss: 38.7135\n",
      "Epoch 40/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 1.0247 - avg_mask_rec_loss: 5.4238 - loss: 38.6913 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 1.0243 - val_avg_mask_rec_loss: 5.4293 - val_loss: 38.7214\n",
      "Epoch 41/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 1.0242 - avg_mask_rec_loss: 5.4210 - loss: 38.6711 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 1.0237 - val_avg_mask_rec_loss: 5.4112 - val_loss: 38.6094\n",
      "Epoch 42/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 1.0236 - avg_mask_rec_loss: 5.4203 - loss: 38.6635 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 1.0231 - val_avg_mask_rec_loss: 5.4141 - val_loss: 38.6232\n",
      "Epoch 43/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 1.0229 - avg_mask_rec_loss: 5.4165 - loss: 38.6368 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 1.0224 - val_avg_mask_rec_loss: 5.4113 - val_loss: 38.6017\n",
      "Epoch 44/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 1.0222 - avg_mask_rec_loss: 5.4136 - loss: 38.6147 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 1.0216 - val_avg_mask_rec_loss: 5.4129 - val_loss: 38.6070\n",
      "Epoch 45/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 1.0214 - avg_mask_rec_loss: 5.4086 - loss: 38.5802 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 1.0207 - val_avg_mask_rec_loss: 5.4048 - val_loss: 38.5530\n",
      "Epoch 46/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 1.0205 - avg_mask_rec_loss: 5.4058 - loss: 38.5579 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 1.0198 - val_avg_mask_rec_loss: 5.4279 - val_loss: 38.6866\n",
      "Epoch 47/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 1.0196 - avg_mask_rec_loss: 5.4123 - loss: 38.5914 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 1.0188 - val_avg_mask_rec_loss: 5.4144 - val_loss: 38.5997\n",
      "Epoch 48/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 1.0186 - avg_mask_rec_loss: 5.4035 - loss: 38.5327 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 1.0178 - val_avg_mask_rec_loss: 5.4175 - val_loss: 38.6120\n",
      "Epoch 49/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 1.0176 - avg_mask_rec_loss: 5.4000 - loss: 38.5055 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 1.0168 - val_avg_mask_rec_loss: 5.4005 - val_loss: 38.5040\n",
      "Epoch 50/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 1.0165 - avg_mask_rec_loss: 5.3991 - loss: 38.4939 - max_probability: 0.0000e+00 - mean_probability: 0.0000e+00 - min_probability: 0.0000e+00 - prob_sparsity_loss: 0.0000e+00 - reg_loss_closest: 0.0000e+00 - reg_loss_similarity: 0.0000e+00 - task_loss: 0.0000e+00 - val_avg_features_rec_loss: 1.0157 - val_avg_mask_rec_loss: 5.3885 - val_loss: 38.4251\n",
      "\tTabCBM self-supervised training completed\n"
     ]
    }
   ],
   "source": [
    "self_supervised_train_epochs = 50\n",
    "print(\"TabCBM self-supervised training stage...\")\n",
    "ss_tabcbm_hist = ss_tabcbm.fit(\n",
    "    x=x_train_std,\n",
    "    y=y_train,\n",
    "    validation_split=validation_size,\n",
    "    epochs=self_supervised_train_epochs,\n",
    "    batch_size=batch_size,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "print(\"\\tTabCBM self-supervised training completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] Assuming independence between features in TabCBM training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PycharmProjects\\AMMISproject\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"tab_cbm_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"tab_cbm_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ decoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">289</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ encoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ sequential_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">11,516</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ concept_generators_0            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,536</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ concept_generators_1            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,536</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ concept_generators_2            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,536</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ concept_generators_3            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,536</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ concept_generators_4            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,536</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ concept_generators_5            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,536</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)                    │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ decoder (\u001b[38;5;33mFunctional\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m289\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ encoder (\u001b[38;5;33mFunctional\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │         \u001b[38;5;34m1,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ sequential_3 (\u001b[38;5;33mSequential\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │        \u001b[38;5;34m11,516\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ concept_generators_0            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │         \u001b[38;5;34m3,536\u001b[0m │\n",
       "│ (\u001b[38;5;33mSequential\u001b[0m)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ concept_generators_1            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │         \u001b[38;5;34m3,536\u001b[0m │\n",
       "│ (\u001b[38;5;33mSequential\u001b[0m)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ concept_generators_2            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │         \u001b[38;5;34m3,536\u001b[0m │\n",
       "│ (\u001b[38;5;33mSequential\u001b[0m)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ concept_generators_3            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │         \u001b[38;5;34m3,536\u001b[0m │\n",
       "│ (\u001b[38;5;33mSequential\u001b[0m)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ concept_generators_4            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │         \u001b[38;5;34m3,536\u001b[0m │\n",
       "│ (\u001b[38;5;33mSequential\u001b[0m)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ concept_generators_5            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │         \u001b[38;5;34m3,536\u001b[0m │\n",
       "│ (\u001b[38;5;33mSequential\u001b[0m)                    │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">34,645</span> (135.33 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m34,645\u001b[0m (135.33 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">34,417</span> (134.44 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m34,417\u001b[0m (134.44 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">228</span> (912.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m228\u001b[0m (912.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# First we will instantiate a new TabCBM that is NOT in self-supervised mode,\n",
    "# and we will load its weights so that they are the same as the model whose\n",
    "# mask generators have been pre-trained using the SS loss.\n",
    "tabcbm_supervised = TabCBM(\n",
    "    self_supervised_mode=False,\n",
    "    # Notice how we provide as concept generators the concept generators of the\n",
    "    # SS TabCBM:\n",
    "    concept_generators=ss_tabcbm.concept_generators,\n",
    "    # as well as the feature probability masks:\n",
    "    prior_masks=ss_tabcbm.feature_probabilities,\n",
    "    **tab_cbm_params,\n",
    ")\n",
    "tabcbm_supervised.compile(optimizer=tf.keras.optimizers.Adam(learning_rate))\n",
    "tabcbm_supervised.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TabCBM self-supervised training stage...\n",
      "Epoch 1/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - accuracy: 0.4257 - avg_concept_size: 17.5381 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 3.2145 - max_probability: 0.7157 - mean_probability: 0.4860 - min_probability: 0.2578 - prob_sparsity_loss: 2.4302 - reg_loss_closest: 0.0125 - reg_loss_similarity: 0.2339 - task_loss: 0.5629 - val_accuracy: 0.4157 - val_loss: 3.0219 - val_prob_sparsity_loss: 2.2212 - val_reg_loss_closest: 0.0151 - val_reg_loss_similarity: 0.2326 - val_task_loss: 0.5832\n",
      "Epoch 2/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.4272 - avg_concept_size: 13.5139 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 2.9097 - max_probability: 0.6621 - mean_probability: 0.4306 - min_probability: 0.2157 - prob_sparsity_loss: 2.1528 - reg_loss_closest: 0.0156 - reg_loss_similarity: 0.2327 - task_loss: 0.5398 - val_accuracy: 0.4157 - val_loss: 2.7505 - val_prob_sparsity_loss: 1.9511 - val_reg_loss_closest: 0.0152 - val_reg_loss_similarity: 0.2326 - val_task_loss: 0.5820\n",
      "Epoch 3/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.4265 - avg_concept_size: 8.5558 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 2.6412 - max_probability: 0.6021 - mean_probability: 0.3773 - min_probability: 0.1809 - prob_sparsity_loss: 1.8864 - reg_loss_closest: 0.0157 - reg_loss_similarity: 0.2326 - task_loss: 0.5379 - val_accuracy: 0.4157 - val_loss: 2.4905 - val_prob_sparsity_loss: 1.6977 - val_reg_loss_closest: 0.0156 - val_reg_loss_similarity: 0.2328 - val_task_loss: 0.5756\n",
      "Epoch 4/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.4270 - avg_concept_size: 3.5629 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 2.3930 - max_probability: 0.5383 - mean_probability: 0.3277 - min_probability: 0.1524 - prob_sparsity_loss: 1.6383 - reg_loss_closest: 0.0159 - reg_loss_similarity: 0.2327 - task_loss: 0.5378 - val_accuracy: 0.4157 - val_loss: 2.2662 - val_prob_sparsity_loss: 1.4670 - val_reg_loss_closest: 0.0157 - val_reg_loss_similarity: 0.2328 - val_task_loss: 0.5822\n",
      "Epoch 5/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.4252 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 2.1687 - max_probability: 0.4740 - mean_probability: 0.2828 - min_probability: 0.1290 - prob_sparsity_loss: 1.4139 - reg_loss_closest: 0.0160 - reg_loss_similarity: 0.2326 - task_loss: 0.5382 - val_accuracy: 0.4157 - val_loss: 2.0596 - val_prob_sparsity_loss: 1.2621 - val_reg_loss_closest: 0.0156 - val_reg_loss_similarity: 0.2324 - val_task_loss: 0.5807\n",
      "Epoch 6/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.4268 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 1.9718 - max_probability: 0.4125 - mean_probability: 0.2432 - min_probability: 0.1099 - prob_sparsity_loss: 1.2158 - reg_loss_closest: 0.0160 - reg_loss_similarity: 0.2325 - task_loss: 0.5395 - val_accuracy: 0.4157 - val_loss: 1.8804 - val_prob_sparsity_loss: 1.0840 - val_reg_loss_closest: 0.0158 - val_reg_loss_similarity: 0.2325 - val_task_loss: 0.5798\n",
      "Epoch 7/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.4270 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 1.7973 - max_probability: 0.3560 - mean_probability: 0.2088 - min_probability: 0.0942 - prob_sparsity_loss: 1.0441 - reg_loss_closest: 0.0161 - reg_loss_similarity: 0.2325 - task_loss: 0.5368 - val_accuracy: 0.4157 - val_loss: 1.7307 - val_prob_sparsity_loss: 0.9312 - val_reg_loss_closest: 0.0161 - val_reg_loss_similarity: 0.2325 - val_task_loss: 0.5830\n",
      "Epoch 8/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.4263 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 1.6522 - max_probability: 0.3060 - mean_probability: 0.1795 - min_probability: 0.0812 - prob_sparsity_loss: 0.8973 - reg_loss_closest: 0.0162 - reg_loss_similarity: 0.2326 - task_loss: 0.5385 - val_accuracy: 0.4157 - val_loss: 1.6011 - val_prob_sparsity_loss: 0.8014 - val_reg_loss_closest: 0.0160 - val_reg_loss_similarity: 0.2325 - val_task_loss: 0.5833\n",
      "Epoch 9/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.4274 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 1.5267 - max_probability: 0.2626 - mean_probability: 0.1545 - min_probability: 0.0703 - prob_sparsity_loss: 0.7727 - reg_loss_closest: 0.0162 - reg_loss_similarity: 0.2324 - task_loss: 0.5378 - val_accuracy: 0.4157 - val_loss: 1.4889 - val_prob_sparsity_loss: 0.6917 - val_reg_loss_closest: 0.0162 - val_reg_loss_similarity: 0.2323 - val_task_loss: 0.5811\n",
      "Epoch 10/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.4290 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 1.4215 - max_probability: 0.2257 - mean_probability: 0.1335 - min_probability: 0.0612 - prob_sparsity_loss: 0.6674 - reg_loss_closest: 0.0163 - reg_loss_similarity: 0.2325 - task_loss: 0.5379 - val_accuracy: 0.4157 - val_loss: 1.3969 - val_prob_sparsity_loss: 0.5989 - val_reg_loss_closest: 0.0160 - val_reg_loss_similarity: 0.2324 - val_task_loss: 0.5816\n",
      "Epoch 11/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.4269 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 1.3340 - max_probability: 0.1943 - mean_probability: 0.1157 - min_probability: 0.0535 - prob_sparsity_loss: 0.5784 - reg_loss_closest: 0.0163 - reg_loss_similarity: 0.2325 - task_loss: 0.5394 - val_accuracy: 0.4157 - val_loss: 1.3178 - val_prob_sparsity_loss: 0.5205 - val_reg_loss_closest: 0.0161 - val_reg_loss_similarity: 0.2326 - val_task_loss: 0.5808\n",
      "Epoch 12/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.4278 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 1.2582 - max_probability: 0.1678 - mean_probability: 0.1006 - min_probability: 0.0470 - prob_sparsity_loss: 0.5031 - reg_loss_closest: 0.0163 - reg_loss_similarity: 0.2325 - task_loss: 0.5389 - val_accuracy: 0.4157 - val_loss: 1.2507 - val_prob_sparsity_loss: 0.4539 - val_reg_loss_closest: 0.0155 - val_reg_loss_similarity: 0.2322 - val_task_loss: 0.5802\n",
      "Epoch 13/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.4272 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 1.1936 - max_probability: 0.1454 - mean_probability: 0.0878 - min_probability: 0.0413 - prob_sparsity_loss: 0.4391 - reg_loss_closest: 0.0162 - reg_loss_similarity: 0.2324 - task_loss: 0.5384 - val_accuracy: 0.4157 - val_loss: 1.1951 - val_prob_sparsity_loss: 0.3972 - val_reg_loss_closest: 0.0162 - val_reg_loss_similarity: 0.2324 - val_task_loss: 0.5817\n",
      "Epoch 14/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.4302 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 1.1377 - max_probability: 0.1266 - mean_probability: 0.0769 - min_probability: 0.0365 - prob_sparsity_loss: 0.3846 - reg_loss_closest: 0.0163 - reg_loss_similarity: 0.2324 - task_loss: 0.5371 - val_accuracy: 0.4157 - val_loss: 1.1438 - val_prob_sparsity_loss: 0.3487 - val_reg_loss_closest: 0.0163 - val_reg_loss_similarity: 0.2322 - val_task_loss: 0.5792\n",
      "Epoch 15/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.4274 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 1.0919 - max_probability: 0.1106 - mean_probability: 0.0676 - min_probability: 0.0323 - prob_sparsity_loss: 0.3379 - reg_loss_closest: 0.0163 - reg_loss_similarity: 0.2324 - task_loss: 0.5380 - val_accuracy: 0.4157 - val_loss: 1.1034 - val_prob_sparsity_loss: 0.3071 - val_reg_loss_closest: 0.0160 - val_reg_loss_similarity: 0.2326 - val_task_loss: 0.5797\n",
      "Epoch 16/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.4259 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 1.0514 - max_probability: 0.0968 - mean_probability: 0.0595 - min_probability: 0.0287 - prob_sparsity_loss: 0.2977 - reg_loss_closest: 0.0163 - reg_loss_similarity: 0.2324 - task_loss: 0.5375 - val_accuracy: 0.4157 - val_loss: 1.0654 - val_prob_sparsity_loss: 0.2712 - val_reg_loss_closest: 0.0162 - val_reg_loss_similarity: 0.2323 - val_task_loss: 0.5782\n",
      "Epoch 17/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.4277 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 1.0180 - max_probability: 0.0852 - mean_probability: 0.0526 - min_probability: 0.0255 - prob_sparsity_loss: 0.2631 - reg_loss_closest: 0.0163 - reg_loss_similarity: 0.2324 - task_loss: 0.5389 - val_accuracy: 0.4157 - val_loss: 1.0403 - val_prob_sparsity_loss: 0.2401 - val_reg_loss_closest: 0.0162 - val_reg_loss_similarity: 0.2325 - val_task_loss: 0.5840\n",
      "Epoch 18/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.4282 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.9873 - max_probability: 0.0751 - mean_probability: 0.0466 - min_probability: 0.0226 - prob_sparsity_loss: 0.2330 - reg_loss_closest: 0.0163 - reg_loss_similarity: 0.2324 - task_loss: 0.5382 - val_accuracy: 0.4157 - val_loss: 1.0118 - val_prob_sparsity_loss: 0.2130 - val_reg_loss_closest: 0.0163 - val_reg_loss_similarity: 0.2324 - val_task_loss: 0.5826\n",
      "Epoch 19/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.4284 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.9604 - max_probability: 0.0664 - mean_probability: 0.0414 - min_probability: 0.0202 - prob_sparsity_loss: 0.2069 - reg_loss_closest: 0.0163 - reg_loss_similarity: 0.2323 - task_loss: 0.5375 - val_accuracy: 0.4157 - val_loss: 0.9835 - val_prob_sparsity_loss: 0.1894 - val_reg_loss_closest: 0.0161 - val_reg_loss_similarity: 0.2326 - val_task_loss: 0.5776\n",
      "Epoch 20/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.4261 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.9358 - max_probability: 0.0589 - mean_probability: 0.0368 - min_probability: 0.0180 - prob_sparsity_loss: 0.1840 - reg_loss_closest: 0.0161 - reg_loss_similarity: 0.2324 - task_loss: 0.5354 - val_accuracy: 0.4157 - val_loss: 0.9659 - val_prob_sparsity_loss: 0.1687 - val_reg_loss_closest: 0.0160 - val_reg_loss_similarity: 0.2323 - val_task_loss: 0.5809\n",
      "Epoch 21/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.4267 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.9175 - max_probability: 0.0525 - mean_probability: 0.0328 - min_probability: 0.0161 - prob_sparsity_loss: 0.1640 - reg_loss_closest: 0.0163 - reg_loss_similarity: 0.2323 - task_loss: 0.5375 - val_accuracy: 0.4157 - val_loss: 0.9440 - val_prob_sparsity_loss: 0.1505 - val_reg_loss_closest: 0.0163 - val_reg_loss_similarity: 0.2321 - val_task_loss: 0.5777\n",
      "Epoch 22/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.4281 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.9012 - max_probability: 0.0469 - mean_probability: 0.0293 - min_probability: 0.0144 - prob_sparsity_loss: 0.1464 - reg_loss_closest: 0.0163 - reg_loss_similarity: 0.2323 - task_loss: 0.5387 - val_accuracy: 0.4157 - val_loss: 0.9322 - val_prob_sparsity_loss: 0.1345 - val_reg_loss_closest: 0.0157 - val_reg_loss_similarity: 0.2322 - val_task_loss: 0.5811\n",
      "Epoch 23/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.4266 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.8854 - max_probability: 0.0419 - mean_probability: 0.0262 - min_probability: 0.0129 - prob_sparsity_loss: 0.1309 - reg_loss_closest: 0.0162 - reg_loss_similarity: 0.2324 - task_loss: 0.5384 - val_accuracy: 0.4157 - val_loss: 0.9174 - val_prob_sparsity_loss: 0.1204 - val_reg_loss_closest: 0.0164 - val_reg_loss_similarity: 0.2322 - val_task_loss: 0.5812\n",
      "Epoch 24/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.4265 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.8723 - max_probability: 0.0377 - mean_probability: 0.0234 - min_probability: 0.0115 - prob_sparsity_loss: 0.1172 - reg_loss_closest: 0.0162 - reg_loss_similarity: 0.2323 - task_loss: 0.5390 - val_accuracy: 0.4157 - val_loss: 0.9055 - val_prob_sparsity_loss: 0.1080 - val_reg_loss_closest: 0.0161 - val_reg_loss_similarity: 0.2324 - val_task_loss: 0.5812\n",
      "Epoch 25/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.4256 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.8568 - max_probability: 0.0339 - mean_probability: 0.0210 - min_probability: 0.0103 - prob_sparsity_loss: 0.1051 - reg_loss_closest: 0.0162 - reg_loss_similarity: 0.2325 - task_loss: 0.5355 - val_accuracy: 0.4157 - val_loss: 0.8916 - val_prob_sparsity_loss: 0.0969 - val_reg_loss_closest: 0.0160 - val_reg_loss_similarity: 0.2327 - val_task_loss: 0.5780\n",
      "Epoch 26/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.4257 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.8499 - max_probability: 0.0306 - mean_probability: 0.0189 - min_probability: 0.0092 - prob_sparsity_loss: 0.0944 - reg_loss_closest: 0.0161 - reg_loss_similarity: 0.2325 - task_loss: 0.5392 - val_accuracy: 0.4157 - val_loss: 0.8807 - val_prob_sparsity_loss: 0.0871 - val_reg_loss_closest: 0.0163 - val_reg_loss_similarity: 0.2323 - val_task_loss: 0.5777\n",
      "Epoch 27/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.4265 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.8384 - max_probability: 0.0276 - mean_probability: 0.0170 - min_probability: 0.0082 - prob_sparsity_loss: 0.0848 - reg_loss_closest: 0.0161 - reg_loss_similarity: 0.2324 - task_loss: 0.5373 - val_accuracy: 0.4157 - val_loss: 0.8769 - val_prob_sparsity_loss: 0.0783 - val_reg_loss_closest: 0.0161 - val_reg_loss_similarity: 0.2322 - val_task_loss: 0.5825\n",
      "Epoch 28/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.4265 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.8310 - max_probability: 0.0250 - mean_probability: 0.0153 - min_probability: 0.0074 - prob_sparsity_loss: 0.0763 - reg_loss_closest: 0.0161 - reg_loss_similarity: 0.2323 - task_loss: 0.5384 - val_accuracy: 0.4157 - val_loss: 0.8642 - val_prob_sparsity_loss: 0.0705 - val_reg_loss_closest: 0.0160 - val_reg_loss_similarity: 0.2323 - val_task_loss: 0.5775\n",
      "Epoch 29/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.4283 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.8233 - max_probability: 0.0227 - mean_probability: 0.0138 - min_probability: 0.0066 - prob_sparsity_loss: 0.0688 - reg_loss_closest: 0.0161 - reg_loss_similarity: 0.2324 - task_loss: 0.5382 - val_accuracy: 0.4157 - val_loss: 0.8589 - val_prob_sparsity_loss: 0.0636 - val_reg_loss_closest: 0.0159 - val_reg_loss_similarity: 0.2323 - val_task_loss: 0.5789\n",
      "Epoch 30/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.4276 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.8161 - max_probability: 0.0206 - mean_probability: 0.0124 - min_probability: 0.0059 - prob_sparsity_loss: 0.0620 - reg_loss_closest: 0.0161 - reg_loss_similarity: 0.2325 - task_loss: 0.5377 - val_accuracy: 0.4157 - val_loss: 0.8518 - val_prob_sparsity_loss: 0.0574 - val_reg_loss_closest: 0.0161 - val_reg_loss_similarity: 0.2322 - val_task_loss: 0.5783\n",
      "Epoch 31/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.4266 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.8086 - max_probability: 0.0188 - mean_probability: 0.0112 - min_probability: 0.0053 - prob_sparsity_loss: 0.0560 - reg_loss_closest: 0.0162 - reg_loss_similarity: 0.2325 - task_loss: 0.5363 - val_accuracy: 0.4157 - val_loss: 0.8491 - val_prob_sparsity_loss: 0.0519 - val_reg_loss_closest: 0.0150 - val_reg_loss_similarity: 0.2323 - val_task_loss: 0.5800\n",
      "Epoch 32/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.4256 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.8030 - max_probability: 0.0173 - mean_probability: 0.0101 - min_probability: 0.0048 - prob_sparsity_loss: 0.0506 - reg_loss_closest: 0.0161 - reg_loss_similarity: 0.2323 - task_loss: 0.5362 - val_accuracy: 0.4157 - val_loss: 0.8401 - val_prob_sparsity_loss: 0.0469 - val_reg_loss_closest: 0.0159 - val_reg_loss_similarity: 0.2326 - val_task_loss: 0.5765\n",
      "Epoch 33/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.4273 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.8000 - max_probability: 0.0161 - mean_probability: 0.0092 - min_probability: 0.0042 - prob_sparsity_loss: 0.0458 - reg_loss_closest: 0.0162 - reg_loss_similarity: 0.2325 - task_loss: 0.5379 - val_accuracy: 0.4157 - val_loss: 0.8368 - val_prob_sparsity_loss: 0.0425 - val_reg_loss_closest: 0.0162 - val_reg_loss_similarity: 0.2324 - val_task_loss: 0.5781\n",
      "Epoch 34/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.4291 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7961 - max_probability: 0.0151 - mean_probability: 0.0083 - min_probability: 0.0038 - prob_sparsity_loss: 0.0415 - reg_loss_closest: 0.0161 - reg_loss_similarity: 0.2324 - task_loss: 0.5383 - val_accuracy: 0.4157 - val_loss: 0.8361 - val_prob_sparsity_loss: 0.0385 - val_reg_loss_closest: 0.0150 - val_reg_loss_similarity: 0.2323 - val_task_loss: 0.5803\n",
      "Epoch 35/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.4266 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7912 - max_probability: 0.0142 - mean_probability: 0.0075 - min_probability: 0.0034 - prob_sparsity_loss: 0.0376 - reg_loss_closest: 0.0160 - reg_loss_similarity: 0.2324 - task_loss: 0.5372 - val_accuracy: 0.4157 - val_loss: 0.8325 - val_prob_sparsity_loss: 0.0350 - val_reg_loss_closest: 0.0161 - val_reg_loss_similarity: 0.2323 - val_task_loss: 0.5813\n",
      "Epoch 36/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.4275 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7885 - max_probability: 0.0137 - mean_probability: 0.0068 - min_probability: 0.0031 - prob_sparsity_loss: 0.0342 - reg_loss_closest: 0.0161 - reg_loss_similarity: 0.2325 - task_loss: 0.5379 - val_accuracy: 0.4157 - val_loss: 0.8321 - val_prob_sparsity_loss: 0.0318 - val_reg_loss_closest: 0.0154 - val_reg_loss_similarity: 0.2324 - val_task_loss: 0.5832\n",
      "Epoch 37/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.4258 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7856 - max_probability: 0.0130 - mean_probability: 0.0062 - min_probability: 0.0027 - prob_sparsity_loss: 0.0311 - reg_loss_closest: 0.0161 - reg_loss_similarity: 0.2325 - task_loss: 0.5382 - val_accuracy: 0.4157 - val_loss: 0.8246 - val_prob_sparsity_loss: 0.0290 - val_reg_loss_closest: 0.0162 - val_reg_loss_similarity: 0.2326 - val_task_loss: 0.5793\n",
      "Epoch 38/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.4286 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7817 - max_probability: 0.0124 - mean_probability: 0.0057 - min_probability: 0.0024 - prob_sparsity_loss: 0.0283 - reg_loss_closest: 0.0161 - reg_loss_similarity: 0.2325 - task_loss: 0.5370 - val_accuracy: 0.4157 - val_loss: 0.8283 - val_prob_sparsity_loss: 0.0264 - val_reg_loss_closest: 0.0158 - val_reg_loss_similarity: 0.2321 - val_task_loss: 0.5856\n",
      "Epoch 39/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.4278 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7801 - max_probability: 0.0117 - mean_probability: 0.0052 - min_probability: 0.0022 - prob_sparsity_loss: 0.0258 - reg_loss_closest: 0.0161 - reg_loss_similarity: 0.2324 - task_loss: 0.5380 - val_accuracy: 0.4157 - val_loss: 0.8242 - val_prob_sparsity_loss: 0.0241 - val_reg_loss_closest: 0.0159 - val_reg_loss_similarity: 0.2324 - val_task_loss: 0.5836\n",
      "Epoch 40/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.4275 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7782 - max_probability: 0.0113 - mean_probability: 0.0047 - min_probability: 0.0020 - prob_sparsity_loss: 0.0236 - reg_loss_closest: 0.0160 - reg_loss_similarity: 0.2324 - task_loss: 0.5382 - val_accuracy: 0.4157 - val_loss: 0.8194 - val_prob_sparsity_loss: 0.0221 - val_reg_loss_closest: 0.0161 - val_reg_loss_similarity: 0.2325 - val_task_loss: 0.5810\n",
      "Epoch 41/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.4264 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7753 - max_probability: 0.0111 - mean_probability: 0.0043 - min_probability: 0.0018 - prob_sparsity_loss: 0.0216 - reg_loss_closest: 0.0162 - reg_loss_similarity: 0.2324 - task_loss: 0.5375 - val_accuracy: 0.4157 - val_loss: 0.8172 - val_prob_sparsity_loss: 0.0202 - val_reg_loss_closest: 0.0159 - val_reg_loss_similarity: 0.2326 - val_task_loss: 0.5803\n",
      "Epoch 42/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.4273 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7744 - max_probability: 0.0106 - mean_probability: 0.0039 - min_probability: 0.0016 - prob_sparsity_loss: 0.0197 - reg_loss_closest: 0.0162 - reg_loss_similarity: 0.2326 - task_loss: 0.5382 - val_accuracy: 0.4157 - val_loss: 0.8151 - val_prob_sparsity_loss: 0.0185 - val_reg_loss_closest: 0.0163 - val_reg_loss_similarity: 0.2322 - val_task_loss: 0.5806\n",
      "Epoch 43/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.4277 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7718 - max_probability: 0.0100 - mean_probability: 0.0036 - min_probability: 0.0014 - prob_sparsity_loss: 0.0181 - reg_loss_closest: 0.0161 - reg_loss_similarity: 0.2325 - task_loss: 0.5373 - val_accuracy: 0.4157 - val_loss: 0.8131 - val_prob_sparsity_loss: 0.0170 - val_reg_loss_closest: 0.0163 - val_reg_loss_similarity: 0.2327 - val_task_loss: 0.5798\n",
      "Epoch 44/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.4275 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7704 - max_probability: 0.0097 - mean_probability: 0.0033 - min_probability: 0.0012 - prob_sparsity_loss: 0.0166 - reg_loss_closest: 0.0163 - reg_loss_similarity: 0.2325 - task_loss: 0.5376 - val_accuracy: 0.4157 - val_loss: 0.8156 - val_prob_sparsity_loss: 0.0156 - val_reg_loss_closest: 0.0151 - val_reg_loss_similarity: 0.2326 - val_task_loss: 0.5825\n",
      "Epoch 45/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.4269 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7696 - max_probability: 0.0093 - mean_probability: 0.0031 - min_probability: 0.0011 - prob_sparsity_loss: 0.0153 - reg_loss_closest: 0.0163 - reg_loss_similarity: 0.2325 - task_loss: 0.5382 - val_accuracy: 0.4157 - val_loss: 0.8118 - val_prob_sparsity_loss: 0.0144 - val_reg_loss_closest: 0.0164 - val_reg_loss_similarity: 0.2326 - val_task_loss: 0.5812\n",
      "Epoch 46/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.4296 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7673 - max_probability: 0.0092 - mean_probability: 0.0028 - min_probability: 9.8632e-04 - prob_sparsity_loss: 0.0141 - reg_loss_closest: 0.0163 - reg_loss_similarity: 0.2325 - task_loss: 0.5369 - val_accuracy: 0.4157 - val_loss: 0.8075 - val_prob_sparsity_loss: 0.0133 - val_reg_loss_closest: 0.0162 - val_reg_loss_similarity: 0.2322 - val_task_loss: 0.5782\n",
      "Epoch 47/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.4268 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7670 - max_probability: 0.0092 - mean_probability: 0.0026 - min_probability: 8.7413e-04 - prob_sparsity_loss: 0.0131 - reg_loss_closest: 0.0163 - reg_loss_similarity: 0.2325 - task_loss: 0.5378 - val_accuracy: 0.4157 - val_loss: 0.8086 - val_prob_sparsity_loss: 0.0123 - val_reg_loss_closest: 0.0160 - val_reg_loss_similarity: 0.2324 - val_task_loss: 0.5799\n",
      "Epoch 48/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.4266 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7649 - max_probability: 0.0091 - mean_probability: 0.0024 - min_probability: 7.7941e-04 - prob_sparsity_loss: 0.0121 - reg_loss_closest: 0.0167 - reg_loss_similarity: 0.2325 - task_loss: 0.5370 - val_accuracy: 0.4157 - val_loss: 0.8061 - val_prob_sparsity_loss: 0.0114 - val_reg_loss_closest: 0.0170 - val_reg_loss_similarity: 0.2324 - val_task_loss: 0.5792\n",
      "Epoch 49/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.4230 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7639 - max_probability: 0.0088 - mean_probability: 0.0022 - min_probability: 6.8438e-04 - prob_sparsity_loss: 0.0112 - reg_loss_closest: 0.0165 - reg_loss_similarity: 0.2325 - task_loss: 0.5367 - val_accuracy: 0.4157 - val_loss: 0.8092 - val_prob_sparsity_loss: 0.0106 - val_reg_loss_closest: 0.0140 - val_reg_loss_similarity: 0.2328 - val_task_loss: 0.5798\n",
      "Epoch 50/50\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.4262 - avg_concept_size: 0.0000e+00 - avg_features_rec_loss: 0.0000e+00 - avg_mask_rec_loss: 0.0000e+00 - loss: 0.7631 - max_probability: 0.0086 - mean_probability: 0.0021 - min_probability: 6.0685e-04 - prob_sparsity_loss: 0.0105 - reg_loss_closest: 0.0166 - reg_loss_similarity: 0.2325 - task_loss: 0.5368 - val_accuracy: 0.4157 - val_loss: 0.8061 - val_prob_sparsity_loss: 0.0099 - val_reg_loss_closest: 0.0168 - val_reg_loss_similarity: 0.2323 - val_task_loss: 0.5807\n",
      "\tTabCBM supervised training completed\n"
     ]
    }
   ],
   "source": [
    "max_epochs = 50   \n",
    "print(\"TabCBM self-supervised training stage...\")\n",
    "\n",
    "tabcbm_hist = tabcbm_supervised.fit(\n",
    "    x=x_train_std,\n",
    "    y=y_train,\n",
    "    validation_split=validation_size,\n",
    "    epochs=max_epochs,\n",
    "    batch_size=batch_size,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "print(\"\\tTabCBM supervised training completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate TabCBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n"
     ]
    }
   ],
   "source": [
    "test_y_pred, test_concept_scores = tabcbm_supervised.predict(\n",
    "    x_test_std,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12050, 34553)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(tf.math.sigmoid(test_y_pred).numpy() > 0.5).sum(), test_y_pred.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 69.67%\n"
     ]
    }
   ],
   "source": [
    "if np.min(test_y_pred) < 0.0 or np.max(test_y_pred) > 1:\n",
    "        # Then we assume that we have outputed logits\n",
    "        test_preds = tf.math.sigmoid(test_y_pred).numpy()\n",
    "\n",
    "test_preds = (test_preds > 0.5).astype(np.int32)\n",
    "results['acc'] = sklearn.metrics.accuracy_score(\n",
    "    y_test,\n",
    "    test_preds,\n",
    ")\n",
    "results['auc'] = sklearn.metrics.roc_auc_score(\n",
    "    y_test,\n",
    "    test_preds,\n",
    ")\n",
    "\n",
    "print(f\"Accuracy is {results['acc']*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.49567437, 0.56690246, 0.5377383 , 0.4823982 , 0.71265817,\n",
       "        0.5291953 ],\n",
       "       [0.5012155 , 0.49902573, 0.4999965 , 0.50061405, 0.5238639 ,\n",
       "        0.56576735],\n",
       "       [0.5710136 , 0.6701345 , 0.5800061 , 0.5610418 , 0.4773939 ,\n",
       "        0.44498098],\n",
       "       ...,\n",
       "       [0.50121325, 0.5031216 , 0.5003134 , 0.5001966 , 0.5243295 ,\n",
       "        0.56199974],\n",
       "       [0.5009029 , 0.5030297 , 0.50002974, 0.49985534, 0.5234854 ,\n",
       "        0.5568946 ],\n",
       "       [0.5006396 , 0.4971397 , 0.49987555, 0.5003974 , 0.53039616,\n",
       "        0.55005425]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_concept_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasVariable shape=(6, 38), dtype=float32, path=tab_cbm_2/probability_vector_logits>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabcbm_supervised.feature_probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of the calculated and ground-truth masks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresholded concept masks learnt by TabCBM:\n",
      "\tFor concept 0 we are selecting the following features [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0]\n",
      "\tFor concept 1 we are selecting the following features [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0]\n",
      "\tFor concept 2 we are selecting the following features [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0]\n",
      "\tFor concept 3 we are selecting the following features [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0]\n",
      "\tFor concept 4 we are selecting the following features [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0]\n",
      "\tFor concept 5 we are selecting the following features [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0]\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# The masks are stored as logits, so we need to turn them to probabilities using\n",
    "# a sigmoid\n",
    "masks = tf.sigmoid(tabcbm_supervised.feature_probabilities).numpy()\n",
    "print(\"Thresholded concept masks learnt by TabCBM:\")\n",
    "for i, mask in enumerate((masks>0.1).astype(np.int32)):\n",
    "    print(\"\\tFor concept\", i, \"we are selecting the following features\", mask)\n",
    "print(\"-\" * 80)\n",
    "print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load pretrained TabCBM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "<class 'tabcbm.models.tabcbm.TabCBM'> could not be deserialized properly. Please ensure that components that are Python object instances (layers, models, etc.) returned by `get_config()` are explicitly deserialized in the model's `from_config()` method.\n\nconfig={'module': 'tabcbm.models.tabcbm', 'class_name': 'TabCBM', 'config': {'name': 'tab_cbm_1', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}}, 'registered_name': 'TabCBM', 'compile_config': {'loss': None, 'loss_weights': None, 'metrics': None, 'weighted_metrics': None, 'run_eagerly': False, 'steps_per_execution': 1, 'jit_compile': False}}.\n\nException encountered: Unable to revive model from config. When overriding the `get_config()` method, make sure that the returned config contains all items used as arguments in the  constructor to <class 'tabcbm.models.tabcbm.TabCBM'>, which is the default behavior. You can override this default behavior by defining a `from_config(cls, config)` class method to specify how to create an instance of TabCBM from its config.\n\nReceived config={'name': 'tab_cbm_1', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}}\n\nError encountered during deserialization: TabCBM.__init__() missing 4 required positional arguments: 'features_to_concepts_model', 'concepts_to_labels_model', 'latent_dims', and 'n_concepts'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32md:\\PycharmProjects\\AMMISproject\\venv\\Lib\\site-packages\\keras\\src\\models\\model.py:533\u001b[0m, in \u001b[0;36mModel.from_config\u001b[1;34m(cls, config, custom_objects)\u001b[0m\n\u001b[0;32m    532\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 533\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    534\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mTypeError\u001b[0m: TabCBM.__init__() missing 4 required positional arguments: 'features_to_concepts_model', 'concepts_to_labels_model', 'latent_dims', and 'n_concepts'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32md:\\PycharmProjects\\AMMISproject\\venv\\Lib\\site-packages\\keras\\src\\saving\\serialization_lib.py:718\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[0;32m    717\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 718\u001b[0m     instance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43minner_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    719\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32md:\\PycharmProjects\\AMMISproject\\venv\\Lib\\site-packages\\keras\\src\\models\\model.py:535\u001b[0m, in \u001b[0;36mModel.from_config\u001b[1;34m(cls, config, custom_objects)\u001b[0m\n\u001b[0;32m    534\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 535\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    536\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to revive model from config. When overriding \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    537\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe `get_config()` method, make sure that the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    538\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturned config contains all items used as arguments \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    539\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min the  constructor to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    540\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhich is the default behavior. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    541\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can override this default behavior by defining a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    542\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`from_config(cls, config)` class method to specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    543\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhow to create an \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    544\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstance of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m from its config.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    545\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived config=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    546\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError encountered during deserialization: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    547\u001b[0m     )\n",
      "\u001b[1;31mTypeError\u001b[0m: Unable to revive model from config. When overriding the `get_config()` method, make sure that the returned config contains all items used as arguments in the  constructor to <class 'tabcbm.models.tabcbm.TabCBM'>, which is the default behavior. You can override this default behavior by defining a `from_config(cls, config)` class method to specify how to create an instance of TabCBM from its config.\n\nReceived config={'name': 'tab_cbm_1', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}}\n\nError encountered during deserialization: TabCBM.__init__() missing 4 required positional arguments: 'features_to_concepts_model', 'concepts_to_labels_model', 'latent_dims', and 'n_concepts'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tabcbm_pretrained \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mD:\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mPycharmProjects\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mAMMISproject\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mtrained_tabcbm_4concepts_1500epochs\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mtabcbm_supervised.keras\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\PycharmProjects\\AMMISproject\\venv\\Lib\\site-packages\\keras\\src\\saving\\saving_api.py:182\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[0;32m    179\u001b[0m         is_keras_zip \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_keras_zip \u001b[38;5;129;01mor\u001b[39;00m is_keras_dir:\n\u001b[1;32m--> 182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msaving_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43msafe_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.hdf5\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m legacy_h5_format\u001b[38;5;241m.\u001b[39mload_model_from_hdf5(\n\u001b[0;32m    190\u001b[0m         filepath, custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects, \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m\n\u001b[0;32m    191\u001b[0m     )\n",
      "File \u001b[1;32md:\\PycharmProjects\\AMMISproject\\venv\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:237\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[0;32m    232\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    233\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid filename: expected a `.keras` extension. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    234\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    235\u001b[0m     )\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filepath, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m--> 237\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load_model_from_fileobj\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_mode\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\PycharmProjects\\AMMISproject\\venv\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:314\u001b[0m, in \u001b[0;36m_load_model_from_fileobj\u001b[1;34m(fileobj, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m zf\u001b[38;5;241m.\u001b[39mopen(_CONFIG_FILENAME, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    312\u001b[0m     config_json \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m--> 314\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43m_model_from_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig_json\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_mode\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    318\u001b[0m all_filenames \u001b[38;5;241m=\u001b[39m zf\u001b[38;5;241m.\u001b[39mnamelist()\n\u001b[0;32m    319\u001b[0m weights_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\PycharmProjects\\AMMISproject\\venv\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:303\u001b[0m, in \u001b[0;36m_model_from_config\u001b[1;34m(config_json, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[0;32m    301\u001b[0m \u001b[38;5;66;03m# Construct the model from the configuration file in the archive.\u001b[39;00m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ObjectSharingScope():\n\u001b[1;32m--> 303\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    304\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe_mode\u001b[49m\n\u001b[0;32m    305\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32md:\\PycharmProjects\\AMMISproject\\venv\\Lib\\site-packages\\keras\\src\\saving\\serialization_lib.py:720\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[0;32m    718\u001b[0m     instance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_config(inner_config)\n\u001b[0;32m    719\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 720\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    721\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m could not be deserialized properly. Please\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    722\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m ensure that components that are Python object\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    723\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m instances (layers, models, etc.) returned by\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    724\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `get_config()` are explicitly deserialized in the\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    725\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m model\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms `from_config()` method.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    726\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mconfig=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mException encountered: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    727\u001b[0m     )\n\u001b[0;32m    728\u001b[0m build_config \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbuild_config\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    729\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m build_config \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m instance\u001b[38;5;241m.\u001b[39mbuilt:\n",
      "\u001b[1;31mTypeError\u001b[0m: <class 'tabcbm.models.tabcbm.TabCBM'> could not be deserialized properly. Please ensure that components that are Python object instances (layers, models, etc.) returned by `get_config()` are explicitly deserialized in the model's `from_config()` method.\n\nconfig={'module': 'tabcbm.models.tabcbm', 'class_name': 'TabCBM', 'config': {'name': 'tab_cbm_1', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}}, 'registered_name': 'TabCBM', 'compile_config': {'loss': None, 'loss_weights': None, 'metrics': None, 'weighted_metrics': None, 'run_eagerly': False, 'steps_per_execution': 1, 'jit_compile': False}}.\n\nException encountered: Unable to revive model from config. When overriding the `get_config()` method, make sure that the returned config contains all items used as arguments in the  constructor to <class 'tabcbm.models.tabcbm.TabCBM'>, which is the default behavior. You can override this default behavior by defining a `from_config(cls, config)` class method to specify how to create an instance of TabCBM from its config.\n\nReceived config={'name': 'tab_cbm_1', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}}\n\nError encountered during deserialization: TabCBM.__init__() missing 4 required positional arguments: 'features_to_concepts_model', 'concepts_to_labels_model', 'latent_dims', and 'n_concepts'"
     ]
    }
   ],
   "source": [
    "tabcbm_pretrained = tf.keras.models.load_model(r'D:\\\\PycharmProjects\\\\AMMISproject\\\\trained_tabcbm_4concepts_1500epochs\\\\tabcbm_supervised.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
